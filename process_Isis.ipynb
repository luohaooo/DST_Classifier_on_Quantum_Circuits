{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c9a957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_table('iris.data', header=None)\n",
    "raw_data = np.array(df)\n",
    "pro_data = [[],[],[]]\n",
    "for item in raw_data:\n",
    "    pro_item = str(item[0]).split(',')\n",
    "    pro_item = [eval(pro_item[0]),eval(pro_item[1]),eval(pro_item[2]),eval(pro_item[3]),pro_item[4]]\n",
    "    if pro_item[4] == 'Iris-setosa':    \n",
    "        pro_item[4] = 0\n",
    "        pro_data[0].append(pro_item)\n",
    "    if pro_item[4] == 'Iris-versicolor': \n",
    "        pro_item[4] = 1\n",
    "        pro_data[1].append(pro_item)\n",
    "    if pro_item[4] == 'Iris-virginica':  \n",
    "        pro_item[4] = 2\n",
    "        pro_data[2].append(pro_item)\n",
    "pro_data = np.array(pro_data)\n",
    "train_ratio = 0.8\n",
    "def train_test(all_data, train_ratio):\n",
    "    train_len = round(len(all_data)*train_ratio)\n",
    "    np.random.shuffle(all_data)\n",
    "    train_data = all_data[0:train_len]\n",
    "    test_data = all_data[train_len:len(all_data)]\n",
    "    return[train_data,test_data]\n",
    "# print(train_test(pro_data[0], train_ratio))\n",
    "m = 4 # attribute\n",
    "n = 3 # types\n",
    "# save training and testing data\n",
    "training_set = [[[] for col in range(m)] for row in range(n)]\n",
    "testing_set = [[[] for col in range(m)] for row in range(n)]\n",
    "# for each type\n",
    "for ii in range(n):\n",
    "    x = train_test(pro_data[ii],train_ratio)\n",
    "#     for each attribute\n",
    "    for jj in range(m):\n",
    "        training_set[ii][jj] = x[0][:,jj]\n",
    "        testing_set[ii][jj]=x[1][:,jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8da2797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# EM iteration to estimate GMM coefficients with training data set\n",
    "from sklearn.mixture import GaussianMixture\n",
    "# GMM coefficients\n",
    "components_num = 3\n",
    "weights = [[[[] for item in range(components_num)] for col in range(m)] for row in range(n)]\n",
    "means = [[[[] for item in range(components_num)] for col in range(m)] for row in range(n)]\n",
    "covariances = [[[[] for item in range(components_num)] for col in range(m)] for row in range(n)]\n",
    "for ii in range(n):\n",
    "    for jj in range(m):\n",
    "        gmm_coefficients = GaussianMixture(n_components=3).fit(training_set[ii][jj].reshape(-1, 1))\n",
    "        for item in range(components_num):\n",
    "            weights[ii][jj][item] = gmm_coefficients.weights_[item]\n",
    "            means[ii][jj][item] = gmm_coefficients.means_[item][0]\n",
    "            covariances[ii][jj][item] = gmm_coefficients.covariances_[item][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303aa711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot GMM curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4f7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a9bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BPAs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbba2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining BPAs on quantum circuits and conduct measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc09dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision-making by the combined BPA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710012c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
