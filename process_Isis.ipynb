{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c9a957a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_table('iris.data', header=None)\n",
    "raw_data = np.array(df)\n",
    "pro_data = [[],[],[]]\n",
    "for item in raw_data:\n",
    "    pro_item = str(item[0]).split(',')\n",
    "    pro_item = [eval(pro_item[0]),eval(pro_item[1]),eval(pro_item[2]),eval(pro_item[3]),pro_item[4]]\n",
    "    if pro_item[4] == 'Iris-setosa':    \n",
    "        pro_item[4] = 0\n",
    "        pro_data[0].append(pro_item)\n",
    "    if pro_item[4] == 'Iris-versicolor': \n",
    "        pro_item[4] = 1\n",
    "        pro_data[1].append(pro_item)\n",
    "    if pro_item[4] == 'Iris-virginica':  \n",
    "        pro_item[4] = 2\n",
    "        pro_data[2].append(pro_item)\n",
    "pro_data = np.array(pro_data)\n",
    "train_ratio = 0.8\n",
    "def train_test(all_data, train_ratio):\n",
    "    train_len = round(len(all_data)*train_ratio)\n",
    "    np.random.shuffle(all_data)\n",
    "    train_data = all_data[0:train_len]\n",
    "    test_data = all_data[train_len:len(all_data)]\n",
    "    return[train_data,test_data]\n",
    "# print(train_test(pro_data[0], train_ratio))\n",
    "m = 4 # attribute\n",
    "n = 3 # types\n",
    "# save training and testing data\n",
    "training_set = [[[] for col in range(m)] for row in range(n)]\n",
    "testing_set = [[] for row in range(n)]\n",
    "# for each type\n",
    "for ii in range(n):\n",
    "    x = train_test(pro_data[ii],train_ratio)\n",
    "    testing_set[ii] = x[1][:,0:4]\n",
    "#     for each attribute\n",
    "    for jj in range(m):\n",
    "        training_set[ii][jj] = x[0][:,jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.4, 3.4, 1.7, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.1, 3.5, 1.4, 0.2],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2]]),\n",
       " array([[6.6, 3. , 4.4, 1.4],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5]]),\n",
       " array([[6.5, 3.2, 5.1, 2. ],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [6.3, 3.4, 5.6, 2.4]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da2797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\29265\\.conda\\envs\\quenv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# EM iteration to estimate GMM coefficients with training data set\n",
    "from sklearn.mixture import GaussianMixture\n",
    "# GMM coefficients\n",
    "components_num = 3\n",
    "weights = [[[[] for item in range(components_num)] for col in range(m)] for row in range(n)]\n",
    "means = [[[[] for item in range(components_num)] for col in range(m)] for row in range(n)]\n",
    "covariances = [[[[] for item in range(components_num)] for col in range(m)] for row in range(n)]\n",
    "for ii in range(n):\n",
    "    for jj in range(m):\n",
    "        gmm_coefficients = GaussianMixture(n_components=3).fit(training_set[ii][jj].reshape(-1, 1))\n",
    "        for item in range(components_num):\n",
    "            weights[ii][jj][item] = gmm_coefficients.weights_[item]\n",
    "            means[ii][jj][item] = gmm_coefficients.means_[item][0]\n",
    "            covariances[ii][jj][item] = gmm_coefficients.covariances_[item][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303aa711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot GMM curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3a9bbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 4.1903814209289186e-42,\n",
       " 0.0,\n",
       " 2.313859356216941e-22,\n",
       " 0.0,\n",
       " 9.695953256934017e-64]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate BPAs\n",
    "def calc_Gaussian(mean,cov,x):\n",
    "    return (1/np.sqrt(2*np.pi*cov))*np.exp(-np.square(x-mean)/(2*cov))\n",
    "\n",
    "def calc_mix_Gaussian(weights,means,covs,x):\n",
    "    components_num = len(weights)\n",
    "    prob = 0\n",
    "    for item in range(components_num):\n",
    "        prob += weights[item]*calc_Gaussian(means[item],covs[item],x)\n",
    "    return prob[0]\n",
    "\n",
    "def generate_BPAs(x, weights, means, covariances):\n",
    "    # x: input testing data (4 atrributes)\n",
    "    attributes_num = len(x)\n",
    "    types_num = len(means)\n",
    "    # BPAs for each attribute\n",
    "    BPAs = [[] for attribute in range(attributes_num)]\n",
    "    for attribute in range(attributes_num):\n",
    "        attribute_value = x[attribute]\n",
    "        # calculate GMM distribution value\n",
    "        f = [[] for type in range(types_num)]\n",
    "        for type in range(types_num):\n",
    "            f[type] = calc_mix_Gaussian(weights[type][attribute],means[type][attribute],covariances[type][attribute],attribute_value)\n",
    "        f = np.array(f)\n",
    "        # calculate pi_0 and pi_1\n",
    "        pi1 = f/max(f)\n",
    "        pi0 = np.ones(types_num)-pi1\n",
    "        # calculate BPA and record\n",
    "        dimension = 2**types_num\n",
    "        BPA = [[] for ii in range(dimension)]\n",
    "        for ii in range(dimension):\n",
    "            # binary represenation\n",
    "            bits = \"{:0>10b}\".format(ii)\n",
    "            # mass\n",
    "            m = 1\n",
    "            for jj in range(types_num):\n",
    "                bit = bits[-(jj+1)]\n",
    "                if bit == '1':\n",
    "                    m *= pi1[jj]\n",
    "                if bit == '0':\n",
    "                    m *= pi0[jj]\n",
    "            BPA[ii] = m\n",
    "        BPAs[attribute] = BPA\n",
    "    return BPAs\n",
    "\n",
    "x = generate_BPAs(testing_set[0][0], weights, means, covariances)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbba2cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining BPAs on quantum circuits and conduct measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc09dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision-making by the combined BPA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
